---
layout: page
title: Research
published: true
---

#### Book

Alvarez, R. Michael, Nicholas J. Adams-Cohen, Seo-young Silvia Kim, Yimeng Li. 2020. ["Securing Elections: How Data-Driven Election Monitoring Can Improve Democracy."](https://www.cambridge.org/core/elements/securing-american-elections/44DB59AB97CD8538ABCC6AD0AD00CCF4) Cambridge University Press.

--------------------------------------

#### Peer Reviewed Journal Articles

- Kim, Seo-young Silvia Kim, Akhil Bandreddi, and R. Michael Alvarez. 2024. ["Why Vote in Person in a Pandemic? Using Machine Learning to Predict Voting Methods."](https://doi.org/10.1111/ssqu.13380) Social Science Quarterly.
    - [Replication archive](https://github.com/sysilviakim/coloradoVotes)
- Kim, Seo-young Silvia, Jan Zilinsky, and Brian Brew. 2024. ["Donate To Help Us Fight Back: Mobilization Rhetoric in Political Fundraising."](https://journals.sagepub.com/doi/10.1177/13540688241235901) Party Politics.
- Kim, Seo-young Silvia, and Jan Zilinsky. 2024. ["Division Does Not Imply Predictability: Demographics Continue to Reveal Little About Voting and Partisanship."](https://link.springer.com/article/10.1007/s11109-022-09816-z) Political Behavior. 46(1):67-87.
    - [Replication archive](https://github.com/sysilviakim/surveyML)
- Kim, Seo-young Silvia. 2023. ["Automatic Voter Re-registration as a Housewarming Gift: Quantifying Causal Effects on Turnout Using Movers."](https://doi.org/10.1017/S0003055422000983) American Political Science Review 117(3): 1137–44.
    - [Replication archive](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ILKRK2) 
    - [Presentation slides used at Emory University, Nov 3, 2022](https://www.dropbox.com/scl/fi/vp6ow58dg6gx7izct0b53/emory-slides.pdf?rlkey=p1mwkz56pc3ck2cvprzu79i7u&raw=1)
    - Article on the [The Conversation](https://theconversation.com/automatic-voter-reregistration-can-substantially-boost-turnout-193492)
- Lopez, Jennifer, R. Michael Alvarez, and Seo-young Silvia Kim. 2022. ["Latinos, Group Identity, and Equal Opportunity on the 2020 California Ballot."](https://doi.org/10.1111/ssqu.13217) Social Science Quarterly. 103(7): 1572-86.
    - [Replication archive](https://github.com/sysilviakim/propSurveyCA)
- Cao, Jian, Seo-young Silvia Kim, and R. Michael Alvarez. 2022. ["Bayesian Analysis of State Voter Registration Database Integrity."](https://doi.org/10.1515/spp-2021-0016) Statistics, Politics and Policy 13(1): 19–40.
    - [Replication archive](https://github.com/sysilviakim/CA-Anomaly-2020)
- Kim, Seo-young Silvia, Hannah Lebovits, and Sarah Shugars. 2022.  ["Networking 101 for Graduate Students: Building a Bigger Table."](https://doi.org/10.1017/S1049096521001025) PS: Political Science & Politics 55(2): 307–12.
- Kim, Seo-young Silvia, R. Michael Alvarez, and Christina M. Ramirez. 2020. ["Who Voted in 2016? Using Fuzzy Forests to Understand Voter Turnout."](https://onlinelibrary.wiley.com/doi/abs/10.1111/ssqu.12777) Social Science Quarterly 101(2): 978–88.
    - [Replication archive](https://github.com/sysilviakim/turnout2016)
- Alvarez, R. Michael, Jonathan N. Katz, and Seo-young Silvia Kim. 2020. ["Hidden Donors: The Censoring Problem in U.S. Federal Campaign Finance Data."](https://www.liebertpub.com/doi/full/10.1089/elj.2019.0593) Election Law Journal: Rules, Politics, and Policy 19(1): 1–18.
    - [Replication code](https://github.com/sysilviakim/turnout2016)
- Kim, Seo-young Silvia, Spencer Schneider, and R. Michael Alvarez. 2020. ["Evaluating the Quality of Changes in Voter Registration Databases."](https://doi.org/10.1177/1532673X19870512) American Politics Research 48(6): 670–676.
    - [Replication code](https://github.com/sysilviakim/voterdiffR)

--------------------------------------

#### Selected Working Papers

**[Addressing Measurement Errors in Ranking Questions for Social Sciences](https://www.dropbox.com/s/acsxut01ygalxbq/?raw=1) (with Yuki Atsusaka.) <br/>**

Social scientists use ranking questions to study people's opinions and preferences. However, few studies discuss measurement errors arising from their complexity, let alone their statistical consequences and what researchers can do about them. We introduce a statistical framework to improve ranking data analysis by addressing measurement errors in ranking questions. First, we propose a formal framework to define measurement errors from random responses---arbitrary and meaningless responses based on a wide range of random patterns. We then quantify bias due to random responses, show that the bias may change our conclusion in any direction, and clarify why item order randomization alone does not solve the statistical issue. Next, we introduce our methodology based on two key design-based considerations: item order randomization and the addition of paired "anchor" ranking questions with known correct answers. These designs allow researchers to (1) learn about the direction of the bias and (2) estimate the proportion of random responses, enabling our bias-corrected estimator. We illustrate our methods by studying the relative importance of our respondents' partisan identities compared to their race, gender, and religious identities. We find that about 30% of respondents offered random responses and that these responses may well change our substantive conclusions.

**[Support and Preference for Grassroots Fundraising](https://www.dropbox.com/s/jgoprrn5ucheqe6/?raw=1) (with Yimeng Li.) <br/>**

Do Americans support small individual donations over other sources of political fundraising? Small online contributions are becoming more prevalent, and political elites and the media often idealize them as leveling the playing field in the American political ecosystem. However, we have little understanding of whether and, if any, how much the public supports small donations as a campaign funding source over others and whether such preferences translate into tangible changes in political behavior. Using a conjoint experiment via a nationally representative survey of U.S. citizens, we test whether candidates with higher dependence on small individual donors are more likely to be chosen. Surprisingly, candidates relying more on small donors attract a higher likelihood of vote choice and candidate ratings, not just within primaries or for Democrats, but across primaries, general elections, and all partisan affiliations. Moreover, the public believes that there should be more small donations in American elections and that, compared to the current baseline, the ideal composition of campaign funding should rely less on PACs and large individual donations and more on small donations and other sources such as candidate self-financing. Such beliefs are unshaken when presented with information about lawmakers with the highest reliance on small donors, who are generally perceived as outsiders or ideologically extreme.

**[Keep Winning with WinRed? Online Fundraising Platform as the Party's Public Good](https://doi.org/10.33774/apsa-2023-666z2) (with Zhao Li.) <br/>**

What determines the relative importance of extended party networks versus party leaders in parties' campaign strategies? We synthesize theories of party organizations by highlighting the interplay between formal institutions and extended networks, using an example from U.S. campaign finance. Online platforms are increasingly important in political fundraising, and party-wide platform coordination increases efficiency for any party. However, parties' strategies sharply diverged: ActBlue for Democrats was created outside of and run independent of the party leadership, while WinRed for Republicans was created and controlled by party elites. We argue that asymmetries in the composition and incentives of extended party network members allowed ActBlue to grow organically but hindered natural coordination for Republicans. Analyses of platform communications and solicitation strategies show that, indeed, only the GOP actively intervened in members' platform choices to overcome coordination failures. Matched-panel analysis proves the strategy effective; Republican candidates reaped sizable fundraising rewards from joining WinRed.

**[When Do Voter Files Accurately Measure Turnout? How Transitory Voter File Snapshots Impact Research and Representation](https://doi.org/10.33774/apsa-2022-qr0gd) (with Bernard Fraga.) <br/>** 

Voter files are an essential tool for both election research and campaigns, but relatively little work has established best practices for using these data. We focus on how the timing of voter file snapshots affects the most commonly cited advantage of voter file data: accurate measures of who votes. Outlining the panel structure inherent in voter file data, we demonstrate that opposing patterns of accretion and attrition in the voter registration list result in temporally-dependent bias in estimates of voter turnout for a given election. This bias impacts samples for surveys, experiments, or campaign activities by skewing estimates of the potential and actual voter populations; low-propensity voters are particularly impacted. We provide an approach that allows researchers to measure the impact of this bias on their inferences. We then outline methods that measurably reduce this bias, including combining multiple snapshots to preserve the turnout histories of dropped voters.

--------------------------------------

#### Book Reviews

- Kim, Seo-young Silvia. 2023. [“Money in Politics: Self-Enrichment, Campaign Spending, and Golden Parachutes by Simon Weschlev.”](https://doi.org/10.1093/psquar/qqad047) Political Science Quarterly 138(3): 461–63.
- 김서영. (2023). [미국의 연방주의와 민주주의의 퇴보](/img/Kim_2023_의정연구.pdf). 의정연구, 29(1), 207-212.
